{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PEFT(Parameter-Efficient Fine-Tuning) on Pre-trained Model(scFoundation) for Perturbation Prediction",
   "id": "917f174a0d0f216e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this tutorial, we demonstrate how to peft(Parameter-Efficient Fine-Tuning) a pre-trained (scFoundation) model on a new dataset for the perturbation prediction task.",
   "id": "4606cc45ffc3c552"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "please download the scFoundation [pretrained files and checkpoints](https://mailmissouri-my.sharepoint.com/:f:/g/personal/hefe_umsystem_edu/EoCITFRQ1AlCs-fVtoSD_oABgxJU7TGHIyx84kRq_3mw2w?e=wbsd9l) into scFoundation/annotations/models",
   "id": "d3d76ce096f5282"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1: Modify the parameters\n",
    "There are four key settings that the reader needs to modify. The available options are listed below:\n",
    "\n",
    "data_name : Norman/K562,\n",
    "\n",
    "data_dir: {data_path},\n",
    "\n",
    "peft_type: Gene_encoder_prompt/ Gene_token_prompt / prefix_prompt / LoRA,\n",
    "\n",
    "save_pathï¼šPath to output"
   ],
   "id": "83569dc2815349c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='GEARS')\n",
    "parser.add_argument('--data_dir', type=str, default='./data')\n",
    "parser.add_argument('--data_name', type=str, default='Norman')\n",
    "parser.add_argument(\"--peft_type\", type=str, default='Encoder_adapter',\n",
    "                        help=' Encoder_adapter/ Token_adapter / Prefix / LoRA / finetune')\n",
    "parser.add_argument('--result_dir', type=str, default='./results')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: import dependencies",
   "id": "157c42ddf933b5f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from os.path import join as pjoin\n",
    "\n",
    "from scfoundation.perturbation.gears import PertData, GEARS\n"
   ],
   "id": "ee02c5fc49cdb1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parser.add_argument('--split', type=str, default='simulation')\n",
    "parser.add_argument('--seed', type=int, default=1)\n",
    "parser.add_argument('--epochs', type=int, default=20)\n",
    "parser.add_argument('--batch_size', type=int, default=2)\n",
    "parser.add_argument('--test_batch_size', type=int, default=2)\n",
    "parser.add_argument('--train_gene_set_size', type=float, default=0.75)\n",
    "parser.add_argument('--hidden_size', type=int, default=512)\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "parser.add_argument('--model_type', type=str, default='maeautobin')\n",
    "parser.add_argument('--bin_set', type=str, default='autobin_resolution_append')\n",
    "parser.add_argument('--singlecell_model_path', type=str, default='scfoundation/annotation/models/models.ckpt')\n",
    "parser.add_argument('--finetune_method', type=str, default='prompt')\n",
    "parser.add_argument('--mode', type=str, default='v1')\n",
    "parser.add_argument('--accumulation_steps', type=int, default=5)\n",
    "parser.add_argument('--highres', type=int, default=0)\n",
    "parser.add_argument('--lr', type=float, default=0.0002)\n",
    "\n",
    "args = parser.parse_args()"
   ],
   "id": "5fc140553f837e82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 3:start training",
   "id": "ecbdb969abae4d46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "args = parser.parse_args()\n",
    "\n",
    "n_layers_conf = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]  # token\n",
    "# mlp_adapter_conf=[1, 1, 1, 1, 1, 1, 0,0,0,0,0,0]\n",
    "# space_adapter_conf=[1, 1, 1, 1, 1, 1,0,0,0,0,0,0]\n",
    "mlp_adapter_conf = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "space_adapter_conf = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "peft_prompt_relationship = {\n",
    "    \"Encoder_adapter\": \"encoder-prompt\",\n",
    "    \"Token_adapter\": \"head-prompt\",\n",
    "    \"Prefix\": \"prefix-prompt\",\n",
    "    \"LoRA\": \"LoRA\",\n",
    "    \"finetune\": \"finetune\"\n",
    "}\n",
    "\n",
    "prompt_type = peft_prompt_relationship[args.peft_type]\n",
    "num_tokens = 64\n",
    "prompt_settings = {\n",
    "    \"use_prompt\": True,\n",
    "    \"num_tokens\": 64,\n",
    "    \"prompt_type\": prompt_type,\n",
    "    \"n_layers_conf\": n_layers_conf,\n",
    "    \"mlp_adapter_conf\": mlp_adapter_conf,\n",
    "    \"space_adapter_conf\": space_adapter_conf\n",
    "}\n",
    "print(prompt_settings)\n",
    "# get data\n",
    "pert_data = PertData(args.data_dir)\n",
    "# load dataset in paper: norman, adamson, dixit.\n",
    "print(args.data_name)\n",
    "print(args.data_name)\n",
    "try:\n",
    "    if args.data_name in ['norman', 'adamson', 'dixit']:\n",
    "        pert_data.load(data_name = args.data_name)\n",
    "    else:\n",
    "        print('load data')\n",
    "        pert_data.load(data_path = pjoin(args.data_dir, args.data_name))\n",
    "except:\n",
    "    adata = sc.read_h5ad(pjoin(args.data_dir, args.data_name+'.h5ad'))\n",
    "    adata.uns['log1p'] = {}\n",
    "    adata.uns['log1p']['base'] = None\n",
    "    pert_data.new_data_process(dataset_name=args.data_name, adata=adata)\n",
    "\n",
    "# specify data split\n",
    "pert_data.prepare_split(split = args.split, seed = args.seed, train_gene_set_size=args.train_gene_set_size)\n",
    "# get dataloader with batch size\n",
    "pert_data.get_dataloader(batch_size = args.batch_size, test_batch_size = args.test_batch_size)\n",
    "\n",
    "# set up and train a model\n",
    "gears_model = GEARS(pert_data, device = args.device)\n",
    "gears_model.model_initialize(hidden_size = args.hidden_size,\n",
    "                             model_type = args.model_type,\n",
    "                             bin_set=args.bin_set,\n",
    "                             load_path=args.singlecell_model_path,\n",
    "                             finetune_method=args.finetune_method,\n",
    "                             accumulation_steps=args.accumulation_steps,\n",
    "                             mode=args.mode,\n",
    "                             highres=args.highres,\n",
    "                             use_prompt=args.use_prompt,\n",
    "                             num_tokens=num_tokens,\n",
    "                             prompt_type=prompt_type,\n",
    "                             n_layers_conf=n_layers_conf,\n",
    "                            mlp_adapter_conf=mlp_adapter_conf,\n",
    "                            space_adapter_conf=space_adapter_conf\n",
    "                             )\n",
    "gears_model.train(epochs = args.epochs, result_dir=args.result_dir,lr=args.lr)\n",
    "\n",
    "# save model\n",
    "gears_model.save_model(args.result_dir)\n",
    "\n",
    "# save params\n",
    "param_pd = pd.DataFrame(vars(args), index=['params']).T\n",
    "param_pd.to_csv(f'{args.result_dir}/params.csv')\n"
   ],
   "id": "c96a547f2f2cb8f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
